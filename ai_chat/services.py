"""
AI ë¶€ì„œ ë¶„ì„ ì„œë¹„ìŠ¤
ë¶€ì„œë³„ 6ê°œì›” ë¯¸íŒ… ì¢…í•© ë¶„ì„ + ê²¬ì /ë‚©í’ˆ íŒ¨í„´ ë¶„ì„
"""
import json
import os
import logging
from datetime import timedelta
from decimal import Decimal
from django.utils import timezone
from openai import OpenAI

logger = logging.getLogger(__name__)


def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.environ.get('OPENAI_API_KEY', '')
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return OpenAI(api_key=api_key)


# ================================================
# ë°ì´í„° ìˆ˜ì§‘
# ================================================

def gather_meeting_data(department, user, months=6):
    """ë¶€ì„œì˜ ìµœê·¼ Nê°œì›” ë¯¸íŒ… ë°ì´í„° ìˆ˜ì§‘"""
    from reporting.models import History, FollowUp

    cutoff = timezone.now().date() - timedelta(days=months * 30)

    followups = FollowUp.objects.filter(
        user=user, department=department
    )

    meetings = History.objects.filter(
        followup__in=followups,
        action_type='customer_meeting',
    ).filter(
        created_at__date__gte=cutoff
    ).order_by('-created_at')

    meeting_list = []
    for m in meetings:
        entry = {
            'date': (m.meeting_date or m.created_at.date()).strftime('%Y-%m-%d'),
            'customer': m.followup.customer_name if m.followup else 'ë¯¸ì •',
        }
        parts = []
        if m.meeting_situation:
            parts.append(f"[ìƒí™©] {m.meeting_situation}")
        if m.meeting_researcher_quote:
            parts.append(f"[ì—°êµ¬ì› ë°œì–¸] {m.meeting_researcher_quote}")
        if m.meeting_confirmed_facts:
            parts.append(f"[í™•ì¸ëœ ì‚¬ì‹¤] {m.meeting_confirmed_facts}")
        if m.meeting_obstacles:
            parts.append(f"[ì¥ì• ë¬¼] {m.meeting_obstacles}")
        if m.meeting_next_action:
            parts.append(f"[ë‹¤ìŒ ì•¡ì…˜] {m.meeting_next_action}")
        if not parts and m.content:
            parts.append(m.content)
        entry['content'] = '\n'.join(parts)
        meeting_list.append(entry)

    return meeting_list


def gather_quote_delivery_data(department, user):
    """ë¶€ì„œì˜ ê²¬ì /ë‚©í’ˆ ë°ì´í„° ìˆ˜ì§‘ ë° íŒ¨í„´ ë¶„ì„"""
    from reporting.models import Quote, QuoteItem, History, FollowUp, DeliveryItem

    followups = FollowUp.objects.filter(user=user, department=department)
    followup_ids = list(followups.values_list('id', flat=True))

    # ê²¬ì  ë°ì´í„°
    quotes = Quote.objects.filter(
        followup_id__in=followup_ids
    ).select_related('followup').prefetch_related('items__product').order_by('-quote_date')

    quote_list = []
    for q in quotes:
        items = []
        for item in q.items.all():
            items.append({
                'product': item.product.name if item.product else 'ë¯¸ì •',
                'quantity': item.quantity,
                'unit_price': int(item.unit_price) if item.unit_price else 0,
                'subtotal': int(item.subtotal) if item.subtotal else 0,
            })
        quote_list.append({
            'quote_number': q.quote_number,
            'date': q.quote_date.strftime('%Y-%m-%d') if q.quote_date else '',
            'customer': q.followup.customer_name if q.followup else 'ë¯¸ì •',
            'stage': q.get_stage_display(),
            'total_amount': int(q.total_amount) if q.total_amount else 0,
            'converted_to_delivery': q.converted_to_delivery,
            'items': items,
        })

    # ë‚©í’ˆ ë°ì´í„°
    deliveries = History.objects.filter(
        followup_id__in=followup_ids,
        action_type='delivery_schedule',
    ).order_by('-created_at')

    delivery_list = []
    for d in deliveries:
        d_items = DeliveryItem.objects.filter(history=d).select_related('product')
        items = []
        for di in d_items:
            items.append({
                'product': di.product.name if di.product else di.item_name,
                'quantity': di.quantity,
                'unit_price': int(di.unit_price) if di.unit_price else 0,
                'total_price': int(di.total_price) if di.total_price else 0,
            })
        delivery_list.append({
            'date': d.delivery_date.strftime('%Y-%m-%d') if d.delivery_date else d.created_at.strftime('%Y-%m-%d'),
            'customer': d.followup.customer_name if d.followup else 'ë¯¸ì •',
            'amount': int(d.delivery_amount) if d.delivery_amount else 0,
            'items': items,
        })

    # íŒ¨í„´ ê³„ì‚°
    total_quotes = len(quote_list)
    converted_quotes = sum(1 for q in quote_list if q['converted_to_delivery'])
    conversion_rate = round(converted_quotes / total_quotes * 100, 1) if total_quotes > 0 else 0

    # ë‚©í’ˆ ì£¼ê¸° ê³„ì‚°
    delivery_dates = sorted([d['date'] for d in delivery_list if d['date']])
    avg_delivery_interval_days = None
    if len(delivery_dates) >= 2:
        from datetime import datetime
        dates = [datetime.strptime(d, '%Y-%m-%d') for d in delivery_dates]
        intervals = [(dates[i+1] - dates[i]).days for i in range(len(dates)-1)]
        intervals = [abs(iv) for iv in intervals if iv != 0]
        if intervals:
            avg_delivery_interval_days = round(sum(intervals) / len(intervals))

    # ì œí’ˆë³„ ì§‘ê³„
    product_stats = {}
    for q in quote_list:
        for item in q['items']:
            name = item['product']
            if name not in product_stats:
                product_stats[name] = {'quoted': 0, 'delivered': 0, 'quote_amount': 0, 'delivery_amount': 0}
            product_stats[name]['quoted'] += 1
            product_stats[name]['quote_amount'] += item['subtotal']
    for d in delivery_list:
        for item in d['items']:
            name = item['product']
            if name not in product_stats:
                product_stats[name] = {'quoted': 0, 'delivered': 0, 'quote_amount': 0, 'delivery_amount': 0}
            product_stats[name]['delivered'] += 1
            product_stats[name]['delivery_amount'] += item['total_price']

    return {
        'quotes': quote_list,
        'deliveries': delivery_list,
        'summary': {
            'total_quotes': total_quotes,
            'converted_quotes': converted_quotes,
            'conversion_rate': conversion_rate,
            'total_deliveries': len(delivery_list),
            'avg_delivery_interval_days': avg_delivery_interval_days,
            'product_stats': product_stats,
        }
    }


# ================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# ================================================

SYSTEM_PROMPT = """ë„ˆëŠ” B2B ì—°êµ¬ì‹¤ ì˜ì—… CRMì˜ "ë¶€ì„œ ì¢…í•© ë¶„ì„" AIë‹¤.
ì˜ì—… ë‹´ë‹¹ìê°€ íŠ¹ì • ë¶€ì„œ(ì—°êµ¬ì‹¤)ì— ëŒ€í•œ ìµœê·¼ 6ê°œì›” ë¯¸íŒ… ë‚´ì—­ + ê²¬ì /ë‚©í’ˆ ë°ì´í„°ë¥¼ ì œê³µí•˜ë©´,
ì´ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ê°ê´€ì ì¸ PainPointì™€ ì˜ì—… ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•œë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš« ì ˆëŒ€ ê·œì¹™ (ì†Œì„¤ ê¸ˆì§€)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ì…ë ¥ ë°ì´í„°ì— **ëª…ì‹œì ìœ¼ë¡œ ì í˜€ìˆëŠ” ë‚´ìš©**ë§Œ ê·¼ê±°(Evidence)ë¡œ ì‚¬ìš©í•œë‹¤.
2. ì…ë ¥ì— ì—†ëŠ” ì‹¤í—˜, ì¥ë¹„, ìƒí™©, ê°ì •ì„ **ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠëŠ”ë‹¤**.
3. ì¶”ì¸¡ì€ ë°˜ë“œì‹œ ã€Œì‚¬ìš©ì ì¶”ì¸¡ã€ìœ¼ë¡œ í‘œì‹œí•˜ê³ , í™•ì‹ ë„ë¥¼ Lowë¡œ ë‚´ë¦°ë‹¤.
4. ê·¼ê±°ê°€ 1ê°œë„ ì—†ëŠ” PainPointëŠ” **ìƒì„±í•˜ì§€ ì•ŠëŠ”ë‹¤**.
5. Evidence ì¸ìš© ì‹œ ë°˜ë“œì‹œ ë”°ì˜´í‘œ(ã€Œã€)ë¡œ ì›ë¬¸ì„ ì§§ê²Œ ì¸ìš©í•˜ê³  ë‚ ì§œë¥¼ í‘œì‹œí•œë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
í™•ì‹ ë„ ê¸°ì¤€ (ì—„ê²© ì ìš©)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

- **High (70-100)**: ì—¬ëŸ¬ ë¯¸íŒ…ì—ì„œ ë°˜ë³µ í™•ì¸ëœ íŒ¨í„´ + ì§ì ‘ ì¸ìš© ì¡´ì¬
- **Med (40-69)**: 1-2íšŒ ì–¸ê¸‰ ë˜ëŠ” ê°„ì ‘ ì‹œê·¸ë„
- **Low (0-39)**: ë‹¨ì¼ ë‹¨ì„œ ë˜ëŠ” ì¶”ì¸¡ ë¹„ì¤‘ í¼

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PainPoint ì¹´í…Œê³ ë¦¬ (ê³ ì • 8ì¢…)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. budget: ì˜ˆì‚°/ê°€ê²©
2. purchase_process: ê²°ì¬/êµ¬ë§¤ í”„ë¡œì„¸ìŠ¤
3. switching_cost: ì „í™˜ ë¹„ìš©/ì¬ê³  ê³ ì°©
4. performance: ì„±ëŠ¥/ì •í™•ë„
5. compatibility: í˜¸í™˜ì„±/ì‚¬ìš©ì„±
6. delivery: ë‚©ê¸°/ì¬ê³ 
7. trust: ì‹ ë¢°/ë¦¬ìŠ¤í¬
8. priority: ìš°ì„ ìˆœìœ„/ê´€ì‹¬

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

```json
{
  "department_summary": "ë¶€ì„œ(ì—°êµ¬ì‹¤) ì „ì²´ ìƒí™©ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",

  "meeting_insights": [
    {
      "theme": "ë°˜ë³µ ë°œê²¬ëœ ì£¼ìš” í…Œë§ˆ/íŒ¨í„´ (í•œ ì¤„)",
      "details": "êµ¬ì²´ì  ì„¤ëª… (ì–´ë–¤ ë¯¸íŒ…ì—ì„œ ì–´ë–¤ ë‚´ìš©ì´ ë°˜ë³µë˜ëŠ”ì§€)",
      "frequency": "í•´ë‹¹ ë‚´ìš©ì´ ë“±ì¥í•œ ë¯¸íŒ… íšŸìˆ˜ ë˜ëŠ” ë¹„ìœ¨"
    }
  ],

  "quote_delivery_insights": {
    "conversion_analysis": "ê²¬ì â†’ë‚©í’ˆ ì „í™˜ìœ¨ ë¶„ì„ ë° ì˜ë¯¸ í•´ì„",
    "delivery_cycle": "ë‚©í’ˆ ì£¼ê¸° íŒ¨í„´ ì„¤ëª… (ì˜ˆ: í‰ê·  Nì¼ ê°„ê²©, íŠ¹ì • ì‹œê¸° ì§‘ì¤‘ ë“±)",
    "product_trends": "ì œí’ˆë³„ ê²¬ì /ë‚©í’ˆ íŠ¸ë Œë“œ ë¶„ì„",
    "stalled_quotes": [
      {
        "quote_info": "ì „í™˜ ì•ˆ ëœ ê²¬ì  ì •ë³´",
        "possible_reason": "ë¯¸íŒ…ë¡ ê¸°ë°˜ ì¶”ì • ì›ì¸ (ê·¼ê±° ì—†ìœ¼ë©´ 'í™•ì¸ í•„ìš”' ëª…ì‹œ)",
        "suggestion": "ëŒ€ì‘ ì œì•ˆ"
      }
    ]
  },

  "painpoint_cards": [
    {
      "category": "budget|purchase_process|switching_cost|performance|compatibility|delivery|trust|priority",
      "hypothesis": "ê°€ì„¤ í•œ ì¤„",
      "confidence": "high|med|low",
      "confidence_score": 75,
      "evidence": [
        {"type": "quote", "text": "ã€Œì›ë¬¸ ì¸ìš©ã€", "source_section": "[2024-01-15 ë¯¸íŒ…]"}
      ],
      "attribution": "individual|lab|purchase_route|institution",
      "verification_question": "ë‹¤ìŒ ë°©ë¬¸ì—ì„œ í™•ì¸í•  ì§ˆë¬¸",
      "action_if_yes": "ë§ìœ¼ë©´ ì‹¤í–‰í•  ëŒ€ì‘",
      "action_if_no": "ì•„ë‹ˆë©´ ë‹¤ìŒ ë‹¨ê³„",
      "caution": "ì£¼ì˜ì‚¬í•­"
    }
  ],

  "next_actions": [
    {
      "action": "êµ¬ì²´ì  ì‹¤í–‰ ì•¡ì…˜",
      "priority": "high|medium|low",
      "reason": "ì™œ ì´ ì•¡ì…˜ì´ í•„ìš”í•œì§€ (ë°ì´í„° ê·¼ê±°)"
    }
  ],

  "missing_info": {
    "items": ["í™•ì¸ ì•ˆ ëœ ì¤‘ìš” ì •ë³´"],
    "questions": ["ë‹¤ìŒ ë°©ë¬¸ì—ì„œ í™•ì¸í•  ì§ˆë¬¸"]
  }
}
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ìµœì¢… ìê¸°ê²€ì¦
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Evidenceì˜ ëª¨ë“  ì¸ìš©ì´ ì‹¤ì œ ì…ë ¥ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ê°€?
2. ê²¬ì /ë‚©í’ˆ ìˆ˜ì¹˜ê°€ ì…ë ¥ ë°ì´í„°ì™€ ì¼ì¹˜í•˜ëŠ”ê°€?
3. ì…ë ¥ì— ì—†ëŠ” ë‚´ìš©ì„ ë§Œë“¤ì–´ë‚¸ ë¶€ë¶„ì€ ì—†ëŠ”ê°€?
"""


# ================================================
# AI ë¶„ì„ ì‹¤í–‰
# ================================================

def analyze_department(analysis, department, user):
    """
    ë¶€ì„œ ì¢…í•© ë¶„ì„ ì‹¤í–‰

    1. ë¯¸íŒ… ë°ì´í„° ìˆ˜ì§‘ (6ê°œì›”)
    2. ê²¬ì /ë‚©í’ˆ ë°ì´í„° ìˆ˜ì§‘
    3. OpenAI API í˜¸ì¶œ
    4. ê²°ê³¼ ì €ì¥

    Returns: (analysis_data, quote_delivery_data, token_usage)
    """
    client = get_openai_client()
    model = os.environ.get('OPENAI_MODEL_STANDARD', 'gpt-4o')

    # ë°ì´í„° ìˆ˜ì§‘
    meetings = gather_meeting_data(department, user)
    qd_data = gather_quote_delivery_data(department, user)

    # í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
    prompt_parts = []
    prompt_parts.append(f"[ë¶„ì„ ëŒ€ìƒ] {department.company.name} / {department.name}")
    prompt_parts.append(f"[ë¶„ì„ ê¸°ê°„] ìµœê·¼ 6ê°œì›”")
    prompt_parts.append("")

    # ë¯¸íŒ… ë°ì´í„°
    prompt_parts.append(f"â”â”â” ë¯¸íŒ… ê¸°ë¡ ({len(meetings)}ê±´) â”â”â”")
    if meetings:
        for i, m in enumerate(meetings, 1):
            prompt_parts.append(f"\n[ë¯¸íŒ… #{i}] {m['date']} - {m['customer']}")
            prompt_parts.append(m['content'])
    else:
        prompt_parts.append("(ë¯¸íŒ… ê¸°ë¡ ì—†ìŒ)")

    # ê²¬ì  ë°ì´í„°
    prompt_parts.append(f"\nâ”â”â” ê²¬ì  ë°ì´í„° ({len(qd_data['quotes'])}ê±´) â”â”â”")
    if qd_data['quotes']:
        for q in qd_data['quotes']:
            items_str = ', '.join([f"{it['product']}({it['quantity']}ê°œ)" for it in q['items']])
            converted = 'âœ…ë‚©í’ˆì „í™˜' if q['converted_to_delivery'] else 'âŒë¯¸ì „í™˜'
            prompt_parts.append(
                f"- {q['date']} | {q['quote_number']} | {q['customer']} | "
                f"{q['stage']} | {q['total_amount']:,}ì› | {converted} | í’ˆëª©: {items_str}"
            )
    else:
        prompt_parts.append("(ê²¬ì  ë°ì´í„° ì—†ìŒ)")

    # ë‚©í’ˆ ë°ì´í„°
    prompt_parts.append(f"\nâ”â”â” ë‚©í’ˆ ë°ì´í„° ({len(qd_data['deliveries'])}ê±´) â”â”â”")
    if qd_data['deliveries']:
        for d in qd_data['deliveries']:
            items_str = ', '.join([f"{it['product']}({it['quantity']}ê°œ)" for it in d['items']])
            prompt_parts.append(
                f"- {d['date']} | {d['customer']} | {d['amount']:,}ì› | í’ˆëª©: {items_str}"
            )
    else:
        prompt_parts.append("(ë‚©í’ˆ ë°ì´í„° ì—†ìŒ)")

    # ì´ë¯¸ ê³„ì‚°ëœ í†µê³„ ì²¨ë¶€
    summary = qd_data['summary']
    prompt_parts.append(f"\nâ”â”â” ê²¬ì /ë‚©í’ˆ í†µê³„ (ì°¸ê³ ) â”â”â”")
    prompt_parts.append(f"ê²¬ì â†’ë‚©í’ˆ ì „í™˜ìœ¨: {summary['conversion_rate']}% ({summary['converted_quotes']}/{summary['total_quotes']})")
    if summary['avg_delivery_interval_days']:
        prompt_parts.append(f"í‰ê·  ë‚©í’ˆ ê°„ê²©: {summary['avg_delivery_interval_days']}ì¼")
    if summary['product_stats']:
        prompt_parts.append("ì œí’ˆë³„ í˜„í™©:")
        for name, stats in summary['product_stats'].items():
            prompt_parts.append(
                f"  - {name}: ê²¬ì  {stats['quoted']}íšŒ({stats['quote_amount']:,}ì›) / "
                f"ë‚©í’ˆ {stats['delivered']}íšŒ({stats['delivery_amount']:,}ì›)"
            )

    prompt_parts.append("\nìœ„ ë°ì´í„°ë§Œ ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ë¼. ì—†ëŠ” ì •ë³´ëŠ” 'í™•ì¸ í•„ìš”'ë¡œ ì²˜ë¦¬í•˜ë¼.")

    user_prompt = "\n".join(prompt_parts)

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt},
    ]

    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.3,
            max_tokens=4000,
            response_format={"type": "json_object"},
        )

        ai_text = response.choices[0].message.content
        token_usage = response.usage.total_tokens if response.usage else 0

        try:
            analysis_result = json.loads(ai_text)
        except json.JSONDecodeError:
            analysis_result = None
            logger.error(f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {ai_text[:200]}")

        return analysis_result, qd_data, token_usage

    except Exception as e:
        logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        raise
