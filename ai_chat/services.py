"""
AI PainPoint ìƒì„±ê¸° - OpenAI ì„œë¹„ìŠ¤
íŒ©íŠ¸ ê¸°ë°˜ ë¶„ì„ì„ ê°•ì œí•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + API í˜¸ì¶œ
"""
import json
import os
import logging
from openai import OpenAI

logger = logging.getLogger(__name__)

# ================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•µì‹¬: ì†Œì„¤ ê¸ˆì§€, íŒ©íŠ¸ ê°•ì œ)
# ================================================

SYSTEM_PROMPT = """ë„ˆëŠ” B2B ì—°êµ¬ì‹¤ ì˜ì—… CRMì˜ "PainPoint ìƒì„±ê¸°" AIë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš« ì ˆëŒ€ ê·œì¹™ (ì†Œì„¤ ê¸ˆì§€)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ì…ë ¥ í…ìŠ¤íŠ¸ì— **ëª…ì‹œì ìœ¼ë¡œ ì í˜€ìˆëŠ” ë¬¸ì¥**ë§Œ ê·¼ê±°(Evidence)ë¡œ ì‚¬ìš©í•œë‹¤.
2. ì…ë ¥ì— ì—†ëŠ” ì‹¤í—˜, ì¥ë¹„, ìƒí™©, ê°ì •ì„ **ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠëŠ”ë‹¤**.
3. "~ì¼ ìˆ˜ ìˆë‹¤", "~í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤" ê°™ì€ ì¶”ì¸¡ì€ ë°˜ë“œì‹œ ã€Œì‚¬ìš©ì ì¶”ì¸¡ã€ìœ¼ë¡œ í‘œì‹œí•˜ê³ , í™•ì‹ ë„ë¥¼ Lowë¡œ ë‚´ë¦°ë‹¤.
4. ê·¼ê±°ê°€ 1ê°œë„ ì—†ëŠ” PainPointëŠ” **ìƒì„±í•˜ì§€ ì•ŠëŠ”ë‹¤**.
5. ê²€ì¦ ì§ˆë¬¸ì€ ì—°êµ¬ì› ì•ì—ì„œ ê·¸ëŒ€ë¡œ ì½ì—ˆì„ ë•Œ "ì €í¬ëŠ” ì•ˆ ê·¸ëŸ°ë°ìš”?"ë¼ëŠ” ë°˜ì‘ì´ ë‚˜ì˜¤ì§€ ì•Šë„ë¡, **ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ í™•ì¸ëœ ì‚¬ì‹¤ë§Œ** ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•œë‹¤.
6. Evidence ì¸ìš© ì‹œ ë°˜ë“œì‹œ ë”°ì˜´í‘œ(ã€Œã€)ë¡œ ì›ë¬¸ì„ ì§§ê²Œ ì¸ìš©í•˜ê³ , ì–´ë–¤ ì„¹ì…˜ì—ì„œ ì™”ëŠ”ì§€ í‘œì‹œí•œë‹¤.
   ì˜ˆ: ã€Œì¬ê³ ê°€ ë„ˆë¬´ ë§ì´ ìŒ“ì—¬...ã€ â† [ì—°êµ¬ì›ì´ í•œ ë§]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
í™•ì‹ ë„ ê¸°ì¤€ (ì—„ê²© ì ìš©)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

- **High (70-100)**: ì§ì ‘ ì¸ìš© + ì‚¬ì‹¤ ì´ë²¤íŠ¸ê°€ **ë™ì‹œì—** ì¡´ì¬í•˜ê³  ë°˜ë³µ íŒ¨í„´ì´ ëª…í™•
- **Med (40-69)**: í•œ ìª½ë§Œ ê°•í•˜ê±°ë‚˜ ê°„ì ‘ ì‹œê·¸ë„ë§Œ ìˆìŒ
- **Low (0-39)**: ë‹¨ì„œê°€ ì•½í•˜ê±°ë‚˜ ì¶”ì¸¡ ë¹„ì¤‘ì´ í¼. ë°˜ë“œì‹œ "ëˆ„ë½/í™•ì¸ í•„ìš”"ì—ë„ ê¸°ì¬

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PainPoint ì¹´í…Œê³ ë¦¬ (ê³ ì • 8ì¢…, ìƒˆ ë²”ì£¼ ìƒì„± ê¸ˆì§€)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. budget: ì˜ˆì‚°/ê°€ê²©
2. purchase_process: ê²°ì¬/êµ¬ë§¤ í”„ë¡œì„¸ìŠ¤(ê±°ë˜ì²˜/ì„¸ê¸ˆê³„ì‚°ì„œ/êµ¬ë§¤ë‹´ë‹¹)
3. switching_cost: ì „í™˜ ë¹„ìš©/ì¬ê³  ê³ ì°©(ì´ë¯¸ ë§ì´ ìŒ“ì—¬ìˆìŒ/í‘œì¤€ ê³ ì°©)
4. performance: ì„±ëŠ¥/ì •í™•ë„(ë¶„ì£¼ ì˜¤ì°¨/ì¬í˜„ì„±/ëˆ„ìˆ˜/ëë§ºí˜)
5. compatibility: í˜¸í™˜ì„±/ì‚¬ìš©ì„±(íŒ íƒ€ì´íŠ¸/ìƒ¤í”„íŠ¸ ë§ˆëª¨/ì†ëª© í”¼ë¡œ)
6. delivery: ë‚©ê¸°/ì¬ê³ (í’ˆì ˆ/ê¸´ê¸‰/ëŒ€ì²´ í•„ìš”)
7. trust: ì‹ ë¢°/ë¦¬ìŠ¤í¬(ì¸ì¦/ê·¼ê±°ìë£Œ/ì±…ì„ì†Œì¬/ì•ˆì „)
8. priority: ìš°ì„ ìˆœìœ„/ê´€ì‹¬(ë°”ì¨/ê´€ì‹¬ ë‚®ìŒ/ë‹´ë‹¹ì ë¶€ì¬)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CRM ìŠ¤í…Œì´ì§€ ì •ì˜ (ê³ ì •)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì‹ ê·œì ‘ì  / ìƒ˜í”ŒëŒ€ê¸° / ê²¬ì ë°œì†¡ / ê²°ì¬ëŒ€ê¸° / ì¬ë°©ë¬¸ì˜ˆì • / ë³´ë¥˜ / ì¢…ë£Œ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ ìˆœì„œ, JSON)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•œë‹¤. JSON ì™¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.

```json
{
  "summary_3lines": ["ìš”ì•½1", "ìš”ì•½2", "ìš”ì•½3"],
  
  "entities": {
    "people_org": ["ì—°êµ¬ì›ëª…/ë©ëª… ë“±"],
    "products": ["ì œí’ˆ/ë¸Œëœë“œ/ëª¨ë¸"],
    "volumes": ["ë³¼ë¥¨ëŒ€"],
    "competitors": ["ê²½ìŸì‚¬/í˜„ì¬ ì‚¬ìš©í’ˆ"],
    "events": ["ì´ë²¤íŠ¸(ìƒ˜í”Œ/ê²¬ì /ì„œë¹„ìŠ¤ ë“±)"],
    "channel_datetime": ["ì±„ë„/ì¼ì‹œ"]
  },
  
  "signals": {
    "researcher_quotes": [
      {"text": "ì§ì ‘ ì¸ìš© ì›ë¬¸", "source_section": "ì—°êµ¬ì›ì´ í•œ ë§"}
    ],
    "confirmed_facts": [
      {"text": "í™•ì¸ëœ ì‚¬ì‹¤", "source_section": "ë‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤"}
    ],
    "user_guesses": [
      {"text": "ì¶”ì¸¡/í•´ì„ ë‚´ìš©", "source_section": "ì˜¤ëŠ˜ ìƒí™©"}
    ]
  },
  
  "painpoint_cards": [
    {
      "category": "budget|purchase_process|switching_cost|performance|compatibility|delivery|trust|priority",
      "hypothesis": "ê°€ì„¤ í•œ ì¤„",
      "confidence": "high|med|low",
      "confidence_score": 75,
      "evidence": [
        {"type": "quote", "text": "ã€Œì›ë¬¸ ì¸ìš©ã€", "source_section": "[ì—°êµ¬ì›ì´ í•œ ë§]"},
        {"type": "fact", "text": "í™•ì¸ëœ ì‚¬ì‹¤", "source_section": "[ë‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤]"}
      ],
      "attribution": "individual|lab|purchase_route|institution",
      "verification_question": "ë‹¤ìŒ ë°©ë¬¸ì—ì„œ ê·¸ëŒ€ë¡œ ì½ì„ ì§ˆë¬¸",
      "action_if_yes": "ë§ìœ¼ë©´ ì‹¤í–‰í•  ëŒ€ì‘ íŒ¨í‚¤ì§€",
      "action_if_no": "ì•„ë‹ˆë©´ ë‹¤ìŒ ë‹¨ê³„",
      "caution": "í•˜ë©´ ì—­íš¨ê³¼ì¸ í–‰ë™"
    }
  ],
  
  "crm_update": {
    "stage": "CRM ìŠ¤í…Œì´ì§€",
    "tags": ["íƒœê·¸1", "íƒœê·¸2"],
    "must_get_next_visit": "ë‹¤ìŒ ë°©ë¬¸ì—ì„œ ë°˜ë“œì‹œ í™•ë³´í•  1ê°œ",
    "reminder": "ë¦¬ë§ˆì¸ë”/í•  ì¼"
  },
  
  "missing_info": {
    "items": ["ëˆ„ë½ í•­ëª©"],
    "questions": ["í™•ì¸ ì§ˆë¬¸"]
  }
}
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ìµœì¢… ìê¸°ê²€ì¦ (ì¶œë ¥ ì „ ë°˜ë“œì‹œ ì²´í¬)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì¶œë ¥í•˜ê¸° ì „ì— ê° PainPoint ì¹´ë“œì— ëŒ€í•´:
1. Evidenceì˜ ëª¨ë“  ì¸ìš©ì´ ì‹¤ì œ ì…ë ¥ í…ìŠ¤íŠ¸ì— ì¡´ì¬í•˜ëŠ”ê°€? â†’ ì—†ìœ¼ë©´ ì‚­ì œ
2. ê²€ì¦ ì§ˆë¬¸ì„ ì—°êµ¬ì›ì—ê²Œ ê·¸ëŒ€ë¡œ ì½ì—ˆì„ ë•Œ "ì•ˆ ê·¸ëŸ°ë°ìš”?"ë¼ê³  í•  ê°€ëŠ¥ì„±ì€? â†’ ë†’ìœ¼ë©´ ìˆ˜ì • ë˜ëŠ” í™•ì‹ ë„ Lowë¡œ í•˜í–¥
3. ì…ë ¥ì— ì—†ëŠ” ì¥ë¹„/ì‹¤í—˜/ìƒí™©ì„ ë‚´ê°€ ë§Œë“¤ì–´ë‚¸ ë¶€ë¶„ì€? â†’ ìˆìœ¼ë©´ ì‚­ì œ
"""


def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.environ.get('OPENAI_API_KEY', '')
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return OpenAI(api_key=api_key)


def build_user_prompt(followup, meeting_data):
    """
    ë¯¸íŒ…ë¡ ë°ì´í„°ë¡œ ìœ ì € í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    meeting_dataëŠ” ë”•ì…”ë„ˆë¦¬:
    - situation: ì˜¤ëŠ˜ ìƒí™©
    - researcher_quote: ì—°êµ¬ì›ì´ í•œ ë§
    - confirmed_facts: ë‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤
    - obstacles: ì¥ì• ë¬¼/ë°˜ëŒ€
    - next_action: ë‹¤ìŒ ì•¡ì…˜
    - free_text: ììœ  ì…ë ¥ (ìœ„ ì„¹ì…˜ë“¤ì´ ì—†ì„ ë•Œ)
    - channel: ë°©ë¬¸/í†µí™”/ë©”ì¼ ë“±
    - visit_date: ë°©ë¬¸ì¼ (ë¬¸ìì—´)
    """
    researcher = followup.customer_name or 'ë¯¸ì •'
    lab = followup.department.name if followup.department else 'ë¯¸ì •'
    company = followup.company.name if followup.company else 'ë¯¸ì •'
    channel = meeting_data.get('channel', 'ë°©ë¬¸')
    visit_date = meeting_data.get('visit_date', '')

    sections = []
    sections.append(f"ì—°êµ¬ì›/ë©: {researcher}, {lab} ({company})")
    sections.append(f"ì±„ë„: {channel}")
    sections.append(f"ì¼ì‹œ: {visit_date}")
    sections.append("")
    sections.append("ë¯¸íŒ…ë¡:")

    # êµ¬ì¡°í™”ëœ ì„¹ì…˜ì´ ìˆìœ¼ë©´ ì‚¬ìš©
    situation = meeting_data.get('situation', '').strip()
    researcher_quote = meeting_data.get('researcher_quote', '').strip()
    confirmed_facts = meeting_data.get('confirmed_facts', '').strip()
    obstacles = meeting_data.get('obstacles', '').strip()
    next_action = meeting_data.get('next_action', '').strip()
    free_text = meeting_data.get('free_text', '').strip()

    if situation:
        sections.append(f"\nì˜¤ëŠ˜ ìƒí™©:\n{situation}")
    if researcher_quote:
        sections.append(f"\nì—°êµ¬ì›ì´ í•œ ë§(ì§ì ‘ ì¸ìš©):\n{researcher_quote}")
    if confirmed_facts:
        sections.append(f"\në‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤:\n{confirmed_facts}")
    if obstacles:
        sections.append(f"\nì¥ì• ë¬¼/ë°˜ëŒ€:\n{obstacles}")
    if next_action:
        sections.append(f"\në‹¤ìŒ ì•¡ì…˜:\n{next_action}")

    # êµ¬ì¡°í™”ëœ ì„¹ì…˜ì´ ëª¨ë‘ ë¹„ì–´ìˆìœ¼ë©´ ììœ  í…ìŠ¤íŠ¸ ì‚¬ìš©
    if not any([situation, researcher_quote, confirmed_facts, obstacles, next_action]):
        if free_text:
            sections.append(f"\n{free_text}")
        else:
            sections.append("\n(ë¯¸íŒ…ë¡ ë‚´ìš© ì—†ìŒ)")

    sections.append("\nì£¼ì˜: ìœ„ í…ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ ê·¼ê±°ë¥¼ ì°¾ì•„ë¼. ì—†ëŠ” ì •ë³´ëŠ” 'ëˆ„ë½/í™•ì¸ í•„ìš”'ë¡œ ì²˜ë¦¬í•´ë¼.")

    return "\n".join(sections)


def build_context_prompt(room):
    """ì´ì „ PainPoint ì¹´ë“œ + ê²€ì¦ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì£¼ì…"""
    from ai_chat.models import PainPointCard
    
    previous_cards = PainPointCard.objects.filter(
        room=room
    ).exclude(
        verification_status='unverified'
    ).order_by('-created_at')[:5]

    if not previous_cards:
        return ""

    lines = ["\nâ”â”â” ì´ì „ ë¶„ì„ íˆìŠ¤í† ë¦¬ (ì°¸ê³ ìš©) â”â”â”"]
    for card in previous_cards:
        status_map = {'confirmed': 'âœ…í™•ì¸ë¨', 'denied': 'âŒë¶€ì •ë¨'}
        status = status_map.get(card.verification_status, '')
        lines.append(
            f"- [{card.get_category_display()}] {card.hypothesis} â†’ {status}"
            f"{f' (ë©”ëª¨: {card.verification_note})' if card.verification_note else ''}"
        )
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    return "\n".join(lines)


def analyze_meeting(room, meeting_data, followup):
    """
    ë¯¸íŒ…ë¡ì„ ë¶„ì„í•˜ì—¬ PainPoint ì¹´ë“œ ìƒì„±
    
    Returns: (ai_response_text, structured_data, token_usage)
    """
    client = get_openai_client()
    model = os.environ.get('OPENAI_MODEL_STANDARD', 'gpt-4o')
    
    user_prompt = build_user_prompt(followup, meeting_data)
    context_prompt = build_context_prompt(room)
    
    if context_prompt:
        user_prompt = user_prompt + "\n" + context_prompt

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt},
    ]

    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.3,  # ë‚®ì€ temperature = ë” íŒ©íŠ¸ ê¸°ë°˜
            max_tokens=4000,
            response_format={"type": "json_object"},
        )

        ai_text = response.choices[0].message.content
        token_usage = response.usage.total_tokens if response.usage else 0

        # JSON íŒŒì‹±
        try:
            structured = json.loads(ai_text)
        except json.JSONDecodeError:
            structured = None
            logger.error(f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {ai_text[:200]}")

        return ai_text, structured, token_usage

    except Exception as e:
        logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        raise


def chat_with_ai(room, user_message):
    """
    ììœ  ëŒ€í™” (ë¯¸íŒ…ë¡ ë¶„ì„ì´ ì•„ë‹Œ ì¼ë°˜ ì§ˆë¬¸)
    ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ì „ì†¡
    """
    from ai_chat.models import AIChatMessage
    
    client = get_openai_client()
    model = os.environ.get('OPENAI_MODEL_STANDARD', 'gpt-4o')

    # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 20ê°œ)
    previous_messages = AIChatMessage.objects.filter(
        room=room
    ).order_by('-created_at')[:20]

    messages = [{"role": "system", "content": SYSTEM_PROMPT}]

    # ì—­ìˆœìœ¼ë¡œ ê°€ì ¸ì™”ìœ¼ë‹ˆ ë‹¤ì‹œ ì •ë ¬
    for msg in reversed(list(previous_messages)):
        messages.append({
            "role": msg.role,
            "content": msg.content
        })

    messages.append({"role": "user", "content": user_message})

    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.3,
            max_tokens=4000,
        )

        ai_text = response.choices[0].message.content
        token_usage = response.usage.total_tokens if response.usage else 0

        # JSONì¸ì§€ íŒë³„
        structured = None
        try:
            structured = json.loads(ai_text)
        except (json.JSONDecodeError, TypeError):
            pass

        return ai_text, structured, token_usage

    except Exception as e:
        logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        raise
