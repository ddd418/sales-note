"""
AI PainPoint ìƒì„±ê¸° - OpenAI ì„œë¹„ìŠ¤
íŒ©íŠ¸ ê¸°ë°˜ ë¶„ì„ì„ ê°•ì œí•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + API í˜¸ì¶œ
"""
import json
import os
import logging
from openai import OpenAI

logger = logging.getLogger(__name__)

# ================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•µì‹¬: ì†Œì„¤ ê¸ˆì§€, íŒ©íŠ¸ ê°•ì œ)
# ================================================

SYSTEM_PROMPT = """ë„ˆëŠ” B2B ì—°êµ¬ì‹¤ ì˜ì—… CRMì˜ "PainPoint ìƒì„±ê¸°" AIë‹¤.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš« ì ˆëŒ€ ê·œì¹™ (ì†Œì„¤ ê¸ˆì§€)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ì…ë ¥ í…ìŠ¤íŠ¸ì— **ëª…ì‹œì ìœ¼ë¡œ ì í˜€ìˆëŠ” ë¬¸ì¥**ë§Œ ê·¼ê±°(Evidence)ë¡œ ì‚¬ìš©í•œë‹¤.
2. ì…ë ¥ì— ì—†ëŠ” ì‹¤í—˜, ì¥ë¹„, ìƒí™©, ê°ì •ì„ **ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠëŠ”ë‹¤**.
3. "~ì¼ ìˆ˜ ìˆë‹¤", "~í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤" ê°™ì€ ì¶”ì¸¡ì€ ë°˜ë“œì‹œ ã€Œì‚¬ìš©ì ì¶”ì¸¡ã€ìœ¼ë¡œ í‘œì‹œí•˜ê³ , í™•ì‹ ë„ë¥¼ Lowë¡œ ë‚´ë¦°ë‹¤.
4. ê·¼ê±°ê°€ 1ê°œë„ ì—†ëŠ” PainPointëŠ” **ìƒì„±í•˜ì§€ ì•ŠëŠ”ë‹¤**.
5. ê²€ì¦ ì§ˆë¬¸ì€ ì—°êµ¬ì› ì•ì—ì„œ ê·¸ëŒ€ë¡œ ì½ì—ˆì„ ë•Œ "ì €í¬ëŠ” ì•ˆ ê·¸ëŸ°ë°ìš”?"ë¼ëŠ” ë°˜ì‘ì´ ë‚˜ì˜¤ì§€ ì•Šë„ë¡, **ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ í™•ì¸ëœ ì‚¬ì‹¤ë§Œ** ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•œë‹¤.
6. Evidence ì¸ìš© ì‹œ ë°˜ë“œì‹œ ë”°ì˜´í‘œ(ã€Œã€)ë¡œ ì›ë¬¸ì„ ì§§ê²Œ ì¸ìš©í•˜ê³ , ì–´ë–¤ ì„¹ì…˜ì—ì„œ ì™”ëŠ”ì§€ í‘œì‹œí•œë‹¤.
   ì˜ˆ: ã€Œì¬ê³ ê°€ ë„ˆë¬´ ë§ì´ ìŒ“ì—¬...ã€ â† [ì—°êµ¬ì›ì´ í•œ ë§]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
í™•ì‹ ë„ ê¸°ì¤€ (ì—„ê²© ì ìš©)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

- **High (70-100)**: ì§ì ‘ ì¸ìš© + ì‚¬ì‹¤ ì´ë²¤íŠ¸ê°€ **ë™ì‹œì—** ì¡´ì¬í•˜ê³  ë°˜ë³µ íŒ¨í„´ì´ ëª…í™•
- **Med (40-69)**: í•œ ìª½ë§Œ ê°•í•˜ê±°ë‚˜ ê°„ì ‘ ì‹œê·¸ë„ë§Œ ìˆìŒ
- **Low (0-39)**: ë‹¨ì„œê°€ ì•½í•˜ê±°ë‚˜ ì¶”ì¸¡ ë¹„ì¤‘ì´ í¼. ë°˜ë“œì‹œ "ëˆ„ë½/í™•ì¸ í•„ìš”"ì—ë„ ê¸°ì¬

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PainPoint ì¹´í…Œê³ ë¦¬ (ê³ ì • 8ì¢…, ìƒˆ ë²”ì£¼ ìƒì„± ê¸ˆì§€)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. budget: ì˜ˆì‚°/ê°€ê²©
2. purchase_process: ê²°ì¬/êµ¬ë§¤ í”„ë¡œì„¸ìŠ¤(ê±°ë˜ì²˜/ì„¸ê¸ˆê³„ì‚°ì„œ/êµ¬ë§¤ë‹´ë‹¹)
3. switching_cost: ì „í™˜ ë¹„ìš©/ì¬ê³  ê³ ì°©(ì´ë¯¸ ë§ì´ ìŒ“ì—¬ìˆìŒ/í‘œì¤€ ê³ ì°©)
4. performance: ì„±ëŠ¥/ì •í™•ë„(ë¶„ì£¼ ì˜¤ì°¨/ì¬í˜„ì„±/ëˆ„ìˆ˜/ëë§ºí˜)
5. compatibility: í˜¸í™˜ì„±/ì‚¬ìš©ì„±(íŒ íƒ€ì´íŠ¸/ìƒ¤í”„íŠ¸ ë§ˆëª¨/ì†ëª© í”¼ë¡œ)
6. delivery: ë‚©ê¸°/ì¬ê³ (í’ˆì ˆ/ê¸´ê¸‰/ëŒ€ì²´ í•„ìš”)
7. trust: ì‹ ë¢°/ë¦¬ìŠ¤í¬(ì¸ì¦/ê·¼ê±°ìë£Œ/ì±…ì„ì†Œì¬/ì•ˆì „)
8. priority: ìš°ì„ ìˆœìœ„/ê´€ì‹¬(ë°”ì¨/ê´€ì‹¬ ë‚®ìŒ/ë‹´ë‹¹ì ë¶€ì¬)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CRM ìŠ¤í…Œì´ì§€ ì •ì˜ (ê³ ì •)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì‹ ê·œì ‘ì  / ìƒ˜í”ŒëŒ€ê¸° / ê²¬ì ë°œì†¡ / ê²°ì¬ëŒ€ê¸° / ì¬ë°©ë¬¸ì˜ˆì • / ë³´ë¥˜ / ì¢…ë£Œ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ ìˆœì„œ, JSON)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•œë‹¤. JSON ì™¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.

```json
{
  "summary_3lines": ["ìš”ì•½1", "ìš”ì•½2", "ìš”ì•½3"],
  
  "entities": {
    "people_org": ["ì—°êµ¬ì›ëª…/ë©ëª… ë“±"],
    "products": ["ì œí’ˆ/ë¸Œëœë“œ/ëª¨ë¸"],
    "volumes": ["ë³¼ë¥¨ëŒ€"],
    "competitors": ["ê²½ìŸì‚¬/í˜„ì¬ ì‚¬ìš©í’ˆ"],
    "events": ["ì´ë²¤íŠ¸(ìƒ˜í”Œ/ê²¬ì /ì„œë¹„ìŠ¤ ë“±)"],
    "channel_datetime": ["ì±„ë„/ì¼ì‹œ"]
  },
  
  "signals": {
    "researcher_quotes": [
      {"text": "ì§ì ‘ ì¸ìš© ì›ë¬¸", "source_section": "ì—°êµ¬ì›ì´ í•œ ë§"}
    ],
    "confirmed_facts": [
      {"text": "í™•ì¸ëœ ì‚¬ì‹¤", "source_section": "ë‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤"}
    ],
    "user_guesses": [
      {"text": "ì¶”ì¸¡/í•´ì„ ë‚´ìš©", "source_section": "ì˜¤ëŠ˜ ìƒí™©"}
    ]
  },
  
  "painpoint_cards": [
    {
      "category": "budget|purchase_process|switching_cost|performance|compatibility|delivery|trust|priority",
      "hypothesis": "ê°€ì„¤ í•œ ì¤„",
      "confidence": "high|med|low",
      "confidence_score": 75,
      "evidence": [
        {"type": "quote", "text": "ã€Œì›ë¬¸ ì¸ìš©ã€", "source_section": "[ì—°êµ¬ì›ì´ í•œ ë§]"},
        {"type": "fact", "text": "í™•ì¸ëœ ì‚¬ì‹¤", "source_section": "[ë‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤]"}
      ],
      "attribution": "individual|lab|purchase_route|institution",
      "verification_question": "ë‹¤ìŒ ë°©ë¬¸ì—ì„œ ê·¸ëŒ€ë¡œ ì½ì„ ì§ˆë¬¸",
      "action_if_yes": "ë§ìœ¼ë©´ ì‹¤í–‰í•  ëŒ€ì‘ íŒ¨í‚¤ì§€",
      "action_if_no": "ì•„ë‹ˆë©´ ë‹¤ìŒ ë‹¨ê³„",
      "caution": "í•˜ë©´ ì—­íš¨ê³¼ì¸ í–‰ë™"
    }
  ],
  
  "crm_update": {
    "stage": "CRM ìŠ¤í…Œì´ì§€",
    "tags": ["íƒœê·¸1", "íƒœê·¸2"],
    "must_get_next_visit": "ë‹¤ìŒ ë°©ë¬¸ì—ì„œ ë°˜ë“œì‹œ í™•ë³´í•  1ê°œ",
    "reminder": "ë¦¬ë§ˆì¸ë”/í•  ì¼"
  },
  
  "next_action_feedback": {
    "original_action": "ì˜ì—… ë‹´ë‹¹ìê°€ ì‘ì„±í•œ ë‹¤ìŒ ì•¡ì…˜ ì›ë¬¸ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
    "evaluation": "good|weak|risky|missing",
    "feedback": "ë‹¤ìŒ ì•¡ì…˜ì— ëŒ€í•œ êµ¬ì²´ì  í”¼ë“œë°± (1-3ë¬¸ì¥). ì¢‹ì€ ì , ë³´ì™„í•  ì , ë¹ ì§„ ê²ƒì„ ì§šì–´ì¤€ë‹¤.",
    "suggested_actions": ["PainPoint ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ” êµ¬ì²´ì  ë‹¤ìŒ ì•¡ì…˜ 1", "ì¶”ì²œ ì•¡ì…˜ 2", "ì¶”ì²œ ì•¡ì…˜ 3"]
  },
  
  "missing_info": {
    "items": ["ëˆ„ë½ í•­ëª©"],
    "questions": ["í™•ì¸ ì§ˆë¬¸"]
  }
}
```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë‹¤ìŒ ì•¡ì…˜ í”¼ë“œë°± ê¸°ì¤€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë¯¸íŒ…ë¡ì— "ë‹¤ìŒ ì•¡ì…˜"ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ next_action_feedbackì„ ì‘ì„±í•œë‹¤:
- **good**: êµ¬ì²´ì ì´ê³  PainPoint í•´ì†Œì— ì§ì ‘ ì—°ê²°ëœ ì•¡ì…˜
- **weak**: ë°©í–¥ì€ ë§ìœ¼ë‚˜ êµ¬ì²´ì„± ë¶€ì¡± (ì˜ˆ: "ë‹¤ì‹œ ë°©ë¬¸" â†’ ì–¸ì œ, ë¬´ì—‡ì„ ê°€ì§€ê³ ?)
- **risky**: PainPointë¥¼ ì•…í™”ì‹œí‚¤ê±°ë‚˜ ì—­íš¨ê³¼ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì•¡ì…˜
- **missing**: ë‹¤ìŒ ì•¡ì…˜ì´ ë¹„ì–´ìˆê±°ë‚˜, ë°œê²¬ëœ PainPoint ëŒ€ë¹„ ëˆ„ë½ëœ ëŒ€ì‘ì´ ìˆìŒ

suggested_actionsì—ëŠ” ë¶„ì„ëœ PainPoint ê¸°ë°˜ìœ¼ë¡œ **ì˜ì—… ë‹´ë‹¹ìê°€ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ** êµ¬ì²´ì  ì•¡ì…˜ì„ 3ê°œê¹Œì§€ ì œì•ˆí•œë‹¤.
ì˜ˆ: "â—‹â—‹ ì—°êµ¬ì›ì—ê²Œ pH ì¸¡ì • ì •í™•ë„ ë¹„êµ ìë£Œ(Aì‚¬ vs ë‹¹ì‚¬) PDF ì „ë‹¬" ìˆ˜ì¤€ì˜ êµ¬ì²´ì„±.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ìµœì¢… ìê¸°ê²€ì¦ (ì¶œë ¥ ì „ ë°˜ë“œì‹œ ì²´í¬)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì¶œë ¥í•˜ê¸° ì „ì— ê° PainPoint ì¹´ë“œì— ëŒ€í•´:
1. Evidenceì˜ ëª¨ë“  ì¸ìš©ì´ ì‹¤ì œ ì…ë ¥ í…ìŠ¤íŠ¸ì— ì¡´ì¬í•˜ëŠ”ê°€? â†’ ì—†ìœ¼ë©´ ì‚­ì œ
2. ê²€ì¦ ì§ˆë¬¸ì„ ì—°êµ¬ì›ì—ê²Œ ê·¸ëŒ€ë¡œ ì½ì—ˆì„ ë•Œ "ì•ˆ ê·¸ëŸ°ë°ìš”?"ë¼ê³  í•  ê°€ëŠ¥ì„±ì€? â†’ ë†’ìœ¼ë©´ ìˆ˜ì • ë˜ëŠ” í™•ì‹ ë„ Lowë¡œ í•˜í–¥
3. ì…ë ¥ì— ì—†ëŠ” ì¥ë¹„/ì‹¤í—˜/ìƒí™©ì„ ë‚´ê°€ ë§Œë“¤ì–´ë‚¸ ë¶€ë¶„ì€? â†’ ìˆìœ¼ë©´ ì‚­ì œ
"""


def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.environ.get('OPENAI_API_KEY', '')
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return OpenAI(api_key=api_key)


# ================================================
# ì±„íŒ… ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì˜ì—… ì½”ì¹­)
# ================================================

CHAT_SYSTEM_PROMPT = """ë„ˆëŠ” B2B ì—°êµ¬ì‹¤ ì˜ì—…ì„ ë•ëŠ” ì „ë¬¸ ì˜ì—… ì½”ì¹˜ AIë‹¤.

â”â”â” ì—­í•  â”â”â”
- ì´ë¯¸ ë¶„ì„ëœ PainPoint ì¹´ë“œì™€ ë¯¸íŒ…ë¡ì„ ë°”íƒ•ìœ¼ë¡œ, ì˜ì—… ë‹´ë‹¹ìì˜ **í›„ì† ì§ˆë¬¸ì— ì‹¤ìš©ì ìœ¼ë¡œ ë‹µë³€**í•œë‹¤.
- ìƒˆë¡œìš´ ë¯¸íŒ… ì •ë³´ê°€ ì¶”ê°€ë˜ë©´ ê¸°ì¡´ ë¶„ì„ì„ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ë³´ì™„í•œë‹¤.

â”â”â” í•µì‹¬ ì›ì¹™ â”â”â”
1. **íŒ©íŠ¸ ê¸°ë°˜**: ê¸°ì¡´ ë¶„ì„/ë¯¸íŒ…ë¡ì—ì„œ í™•ì¸ëœ ì‚¬ì‹¤ë§Œ ê·¼ê±°ë¡œ ì‚¬ìš©
2. **ì‹¤í–‰ ê°€ëŠ¥**: "~í•˜ì„¸ìš”"ê°€ ì•„ë‹ˆë¼ "ë‹¤ìŒ ë°©ë¬¸ ì‹œ ì´ë ‡ê²Œ ë§í•˜ì„¸ìš”: ..." ìˆ˜ì¤€ì˜ êµ¬ì²´ì  ì•¡ì…˜
3. **ê°„ê²°í•¨**: í•µì‹¬ë§Œ 3-5ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€. ë¶ˆí•„ìš”í•œ ë°˜ë³µ ê¸ˆì§€
4. **í•œêµ­ì–´**: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ëŒ€í™”

â”â”â” ë‹µë³€ ê°€ëŠ¥ ì£¼ì œ â”â”â”
- PainPointë³„ ëŒ€ì‘ ì „ëµ / í™”ë²• ì œì•ˆ
- ë‹¤ìŒ ë°©ë¬¸ ì‹œë‚˜ë¦¬ì˜¤ / ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
- ê²½ìŸì‚¬ ëŒ€ì‘ ì „ëµ
- ê²¬ì /ìƒ˜í”Œ ì§„í–‰ ì¡°ì–¸
- CRM ìŠ¤í…Œì´ì§€ íŒë‹¨ ê·¼ê±°
- ê³ ê°ì˜ êµ¬ë§¤ ì‹ í˜¸ í•´ì„

â”â”â” ê¸ˆì§€ ì‚¬í•­ â”â”â”
- ë¯¸íŒ…ë¡ì— ì—†ëŠ” ì—°êµ¬ì› ë°œì–¸ì„ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠëŠ”ë‹¤
- í™•ì¸ ì•ˆ ëœ ê³ ê° ìƒí™©ì„ ì‚¬ì‹¤ì²˜ëŸ¼ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤
- JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤ (ìì—°ì–´ ëŒ€í™”ë§Œ)

â”â”â” ì¶”ê°€ ë¯¸íŒ… ì •ë³´ê°€ ì…ë ¥ëœ ê²½ìš° â”â”â”
ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ë¯¸íŒ…/í†µí™” ë‚´ìš©ì„ ê³µìœ í•˜ë©´:
1. ê¸°ì¡´ PainPointì™€ì˜ ì—°ê´€ì„±ì„ ì§šì–´ì¤€ë‹¤
2. í™•ì‹ ë„ ë³€í™”ê°€ ìˆìœ¼ë©´ ì•Œë ¤ì¤€ë‹¤ (ì˜ˆ: "ì•ì„œ Lowì˜€ë˜ budget PainPointê°€ ì´ë²ˆ ë°œì–¸ìœ¼ë¡œ Medë¡œ ì˜¬ë¼ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
3. ìƒˆë¡­ê²Œ ë°œê²¬ëœ PainPointê°€ ìˆìœ¼ë©´ ê°„ë‹¨íˆ ì œì•ˆí•œë‹¤
"""


def build_user_prompt(followup, meeting_data):
    """
    ë¯¸íŒ…ë¡ ë°ì´í„°ë¡œ ìœ ì € í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    meeting_dataëŠ” ë”•ì…”ë„ˆë¦¬:
    - situation: ì˜¤ëŠ˜ ìƒí™©
    - researcher_quote: ì—°êµ¬ì›ì´ í•œ ë§
    - confirmed_facts: ë‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤
    - obstacles: ì¥ì• ë¬¼/ë°˜ëŒ€
    - next_action: ë‹¤ìŒ ì•¡ì…˜
    - free_text: ììœ  ì…ë ¥ (ìœ„ ì„¹ì…˜ë“¤ì´ ì—†ì„ ë•Œ)
    - channel: ë°©ë¬¸/í†µí™”/ë©”ì¼ ë“±
    - visit_date: ë°©ë¬¸ì¼ (ë¬¸ìì—´)
    """
    researcher = followup.customer_name or 'ë¯¸ì •'
    lab = followup.department.name if followup.department else 'ë¯¸ì •'
    company = followup.company.name if followup.company else 'ë¯¸ì •'
    channel = meeting_data.get('channel', 'ë°©ë¬¸')
    visit_date = meeting_data.get('visit_date', '')

    sections = []
    sections.append(f"ì—°êµ¬ì›/ë©: {researcher}, {lab} ({company})")
    sections.append(f"ì±„ë„: {channel}")
    sections.append(f"ì¼ì‹œ: {visit_date}")
    sections.append("")
    sections.append("ë¯¸íŒ…ë¡:")

    # êµ¬ì¡°í™”ëœ ì„¹ì…˜ì´ ìˆìœ¼ë©´ ì‚¬ìš©
    situation = meeting_data.get('situation', '').strip()
    researcher_quote = meeting_data.get('researcher_quote', '').strip()
    confirmed_facts = meeting_data.get('confirmed_facts', '').strip()
    obstacles = meeting_data.get('obstacles', '').strip()
    next_action = meeting_data.get('next_action', '').strip()
    free_text = meeting_data.get('free_text', '').strip()

    if situation:
        sections.append(f"\nì˜¤ëŠ˜ ìƒí™©:\n{situation}")
    if researcher_quote:
        sections.append(f"\nì—°êµ¬ì›ì´ í•œ ë§(ì§ì ‘ ì¸ìš©):\n{researcher_quote}")
    if confirmed_facts:
        sections.append(f"\në‚´ê°€ í™•ì¸í•œ ì‚¬ì‹¤:\n{confirmed_facts}")
    if obstacles:
        sections.append(f"\nì¥ì• ë¬¼/ë°˜ëŒ€:\n{obstacles}")
    if next_action:
        sections.append(f"\në‹¤ìŒ ì•¡ì…˜:\n{next_action}")

    # êµ¬ì¡°í™”ëœ ì„¹ì…˜ì´ ëª¨ë‘ ë¹„ì–´ìˆìœ¼ë©´ ììœ  í…ìŠ¤íŠ¸ ì‚¬ìš©
    if not any([situation, researcher_quote, confirmed_facts, obstacles, next_action]):
        if free_text:
            sections.append(f"\n{free_text}")
        else:
            sections.append("\n(ë¯¸íŒ…ë¡ ë‚´ìš© ì—†ìŒ)")

    sections.append("\nì£¼ì˜: ìœ„ í…ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ ê·¼ê±°ë¥¼ ì°¾ì•„ë¼. ì—†ëŠ” ì •ë³´ëŠ” 'ëˆ„ë½/í™•ì¸ í•„ìš”'ë¡œ ì²˜ë¦¬í•´ë¼.")

    return "\n".join(sections)


def build_context_prompt(room):
    """ì´ì „ PainPoint ì¹´ë“œ + ê²€ì¦ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì£¼ì…"""
    from ai_chat.models import PainPointCard
    
    previous_cards = PainPointCard.objects.filter(
        room=room
    ).exclude(
        verification_status='unverified'
    ).order_by('-created_at')[:5]

    if not previous_cards:
        return ""

    lines = ["\nâ”â”â” ì´ì „ ë¶„ì„ íˆìŠ¤í† ë¦¬ (ì°¸ê³ ìš©) â”â”â”"]
    for card in previous_cards:
        status_map = {'confirmed': 'âœ…í™•ì¸ë¨', 'denied': 'âŒë¶€ì •ë¨'}
        status = status_map.get(card.verification_status, '')
        lines.append(
            f"- [{card.get_category_display()}] {card.hypothesis} â†’ {status}"
            f"{f' (ë©”ëª¨: {card.verification_note})' if card.verification_note else ''}"
        )
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    return "\n".join(lines)


def analyze_meeting(room, meeting_data, followup):
    """
    ë¯¸íŒ…ë¡ì„ ë¶„ì„í•˜ì—¬ PainPoint ì¹´ë“œ ìƒì„±
    
    Returns: (ai_response_text, structured_data, token_usage)
    """
    client = get_openai_client()
    model = os.environ.get('OPENAI_MODEL_STANDARD', 'gpt-4o')
    
    user_prompt = build_user_prompt(followup, meeting_data)
    context_prompt = build_context_prompt(room)
    
    if context_prompt:
        user_prompt = user_prompt + "\n" + context_prompt

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt},
    ]

    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.3,  # ë‚®ì€ temperature = ë” íŒ©íŠ¸ ê¸°ë°˜
            max_tokens=4000,
            response_format={"type": "json_object"},
        )

        ai_text = response.choices[0].message.content
        token_usage = response.usage.total_tokens if response.usage else 0

        # JSON íŒŒì‹±
        try:
            structured = json.loads(ai_text)
        except json.JSONDecodeError:
            structured = None
            logger.error(f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {ai_text[:200]}")

        return ai_text, structured, token_usage

    except Exception as e:
        logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        raise


def chat_with_ai(room, user_message):
    """
    ì˜ì—… ì½”ì¹­ ëŒ€í™” - ê¸°ì¡´ PainPoint ë¶„ì„ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
    ìì—°ì–´ ëŒ€í™”ë¡œ í›„ì† ì§ˆë¬¸ / ì „ëµ ì¡°ì–¸ ì œê³µ
    """
    from ai_chat.models import AIChatMessage, PainPointCard
    
    client = get_openai_client()
    model = os.environ.get('OPENAI_MODEL_STANDARD', 'gpt-4o')

    # ---- ê¸°ì¡´ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ----
    context_parts = []

    # 1) ê³ ê° ì •ë³´
    followup = room.followup
    context_parts.append(f"[ê³ ê° ì •ë³´] {followup.customer_name} / {followup.department.name if followup.department else 'ë¶€ì„œ ë¯¸ì •'} / {followup.company.name if followup.company else 'íšŒì‚¬ ë¯¸ì •'}")

    # 2) ê¸°ì¡´ PainPoint ì¹´ë“œ ìš”ì•½
    cards = PainPointCard.objects.filter(room=room).order_by('-confidence_score')
    if cards.exists():
        context_parts.append("\n[ê¸°ì¡´ PainPoint ë¶„ì„ ê²°ê³¼]")
        for card in cards:
            status_map = {'unverified': 'ë¯¸ê²€ì¦', 'confirmed': 'âœ…í™•ì¸', 'denied': 'âŒë¶€ì •'}
            status = status_map.get(card.verification_status, 'ë¯¸ê²€ì¦')
            note = f" (ë©”ëª¨: {card.verification_note})" if card.verification_note else ""
            context_parts.append(
                f"- [{card.get_category_display()}] {card.hypothesis} "
                f"(í™•ì‹ ë„: {card.confidence_score}ì , {status}{note})"
            )
            if card.evidence:
                for ev in card.evidence[:2]:
                    context_parts.append(f"  ê·¼ê±°: {ev.get('text', '')}")

    # 3) ìµœì´ˆ ë¯¸íŒ…ë¡ ë¶„ì„ì˜ ì›ë³¸ ë°ì´í„° (ì²« assistant ë©”ì‹œì§€ì˜ structured_data)
    first_analysis = AIChatMessage.objects.filter(
        room=room, role='assistant', structured_data__isnull=False
    ).order_by('created_at').first()
    if first_analysis and first_analysis.structured_data:
        sd = first_analysis.structured_data
        if sd.get('summary_3lines'):
            context_parts.append("\n[ë¯¸íŒ… 3ì¤„ ìš”ì•½]")
            for line in sd['summary_3lines']:
                context_parts.append(f"- {line}")
        if sd.get('signals', {}).get('researcher_quotes'):
            context_parts.append("\n[ì—°êµ¬ì› ë°œì–¸]")
            for q in sd['signals']['researcher_quotes'][:5]:
                context_parts.append(f"- ã€Œ{q.get('text', '')}ã€")
        if sd.get('missing_info', {}).get('items'):
            context_parts.append("\n[ì•„ì§ í™•ì¸ ì•ˆ ëœ ì •ë³´]")
            for item in sd['missing_info']['items']:
                context_parts.append(f"- {item}")

    context_text = "\n".join(context_parts)

    # ---- ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 10ê°œ) ----
    previous_messages = AIChatMessage.objects.filter(
        room=room
    ).order_by('-created_at')[:10]

    messages = [
        {"role": "system", "content": CHAT_SYSTEM_PROMPT},
        {"role": "user", "content": f"[ë¶„ì„ ì»¨í…ìŠ¤íŠ¸]\n{context_text}\n\nìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì´í›„ ëŒ€í™”ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ì´ ë©”ì‹œì§€ì—ëŠ” ë‹µë³€í•˜ì§€ ë§ê³ , ë‹¤ìŒ ì§ˆë¬¸ì„ ê¸°ë‹¤ë¦¬ì„¸ìš”."},
        {"role": "assistant", "content": "ë„¤, ë¶„ì„ ê²°ê³¼ë¥¼ ìˆ™ì§€í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸í•´ì£¼ì„¸ìš”."},
    ]

    # ì´ì „ ëŒ€í™” ì¶”ê°€ (ì—­ìˆœ â†’ ì •ìˆœ)
    for msg in reversed(list(previous_messages)):
        # ì²« ë¶„ì„ ë©”ì‹œì§€(JSON)ëŠ” ì´ë¯¸ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨í–ˆìœ¼ë¯€ë¡œ ê±´ë„ˆëœ€
        if msg.role == 'assistant' and msg.structured_data and msg == first_analysis:
            continue
        messages.append({
            "role": msg.role,
            "content": msg.content if len(msg.content) < 2000 else msg.content[:2000] + "...(ìƒëµ)"
        })

    messages.append({"role": "user", "content": user_message})

    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.5,
            max_tokens=1500,
        )

        ai_text = response.choices[0].message.content
        token_usage = response.usage.total_tokens if response.usage else 0

        return ai_text, None, token_usage

    except Exception as e:
        logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        raise
